{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61120990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25, Private, 195994, 1st-4th, 2, Never-married, Priv-house-serv, Not-in-family, White, Female, 0, 0, 40, Guatemala, <=50K\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15512/4092766585.py\u001b[0m in \u001b[0;36m<cell line: 191>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mleafNode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'round4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0.8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[0marrow_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrowstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'<-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m     \u001b[0mlenses_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15512/4092766585.py\u001b[0m in \u001b[0;36mlenses_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mlensesTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlenses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlensesLabel\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 创建树\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlensesTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[0mcreatePlot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlensesTree\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 绘制树\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15512/4092766585.py\u001b[0m in \u001b[0;36mcreatePlot\u001b[1;34m(inTree)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[0maxprops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mcreatePlot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0maxprops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m     \u001b[0mplotTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotalW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetNumLeafs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m     \u001b[0mplotTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotalD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetTreeDepth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mplotTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxOff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mplotTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotalW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15512/4092766585.py\u001b[0m in \u001b[0;36mgetNumLeafs\u001b[1;34m(myTree)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;34m\"\"\"获取叶节点的数目\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mnumLeafs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[0mfirstStr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[0msecondDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyTree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirstStr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msecondDict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADKUlEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzCwAEud1AMBPTBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUKmCxAyXYCQ6QKETBcgZLoAIdMFCJkuQMh0AUIXXkAFyl+f4fsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import log\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    \"\"\"\n",
    "    计算给定数据集的香农熵\n",
    "    :param dataSet:给定的数据集\n",
    "    :return:返回香农熵\n",
    "    \"\"\"\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts ={}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] =0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for label in labelCounts.keys():\n",
    "        prob = float(labelCounts[label])/numEntries\n",
    "        shannonEnt -= prob*log(prob,2)\n",
    "    return shannonEnt\n",
    "\n",
    "def splitDataSet(dataSet,axis,value):\n",
    "    \"\"\"按照给定特征划分数据集\"\"\"\n",
    "    retDataSet = []  # 创建新的list对象，作为返回的数据\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis]==value:\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])  # 抽取\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    \"\"\"选择最好的数据集划分方式\"\"\"\n",
    "    numFeatures = len(dataSet[0])-1\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "        # 获取第i个特征值，不重复的值\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)\n",
    "        # 计算每种划分方式的信息熵newEntropy\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet,i,value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob*calcShannonEnt(subDataSet)\n",
    "        # 信息增益是熵的减少或数据无序度的减少\n",
    "        # 比较所有特征中的信息增益，返回最好特征划分的索引值\n",
    "        infoGain = baseEntropy-newEntropy\n",
    "        if infoGain > bestInfoGain:\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature\n",
    "\n",
    "def majorityCnt(classList):\n",
    "    \"\"\"获取出现次数最好的分类名称\"\"\"\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "def createTree(dataSet,labels):\n",
    "    \"\"\"创建树\"\"\"\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    # 如果类别完全相同，则停止继续划分\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    # 遍历完所有特征时返回出现次数最多的类别\n",
    "    if len(dataSet[0]) ==1:\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{}}\n",
    "    del labels[bestFeat]\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet,bestFeat,value),subLabels)\n",
    "    return myTree\n",
    "\n",
    "# 使用文本注解绘制树节点\n",
    "def plotNode(nodeTxt,centerPt,parentPt,nodeType):\n",
    "    \"\"\"绘制带箭头的节点\"\"\"\n",
    "    createPlot.ax1.annotate(nodeTxt,xy=parentPt,xycoords='axes fraction',xytext= centerPt,textcoords='axes fraction',va='center',ha='center',bbox=nodeType,arrowprops=arrow_args)\n",
    "\n",
    "def createPlot():\n",
    "    \"\"\"绘制树节点\"\"\"\n",
    "    fig = plt.figure(1,facecolor='white')\n",
    "    fig.clf()\n",
    "    createPlot.ax1 = plt.subplot(111,frameon=False)\n",
    "    plotNode('决策节点',(0.5,0.1),(0.1,0.5),decisionNode)\n",
    "    plotNode('叶节点',(0.8,0.1),(0.3,0.8),leafNode)\n",
    "    plt.show()\n",
    "\n",
    "def getNumLeafs(myTree):\n",
    "    \"\"\"获取叶节点的数目\"\"\"\n",
    "    numLeafs = 0\n",
    "    firstStr = list(myTree.keys())[0]\n",
    "    secondDict = myTree[firstStr]\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__=='dict':\n",
    "            numLeafs += getNumLeafs(secondDict[key])\n",
    "        else:\n",
    "            numLeafs += 1\n",
    "    return numLeafs\n",
    "\n",
    "def getTreeDepth(myTree):\n",
    "    \"\"\"获取树的层数\"\"\"\n",
    "    maxDepth = 0\n",
    "    firstStr =list(myTree.keys())[0]\n",
    "    secondDict = myTree[firstStr]\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__ =='dict':\n",
    "            thisDepth = 1+getTreeDepth(secondDict[key])\n",
    "        else:\n",
    "            thisDepth = 1\n",
    "        if thisDepth > maxDepth:\n",
    "            maxDepth = thisDepth\n",
    "    return maxDepth\n",
    "\n",
    "def plotMidText(cntPt,parentPt,txtString):\n",
    "    \"\"\"在父子节点间填充文本信息\"\"\"\n",
    "    xMid = (parentPt[0]-cntPt[0])/2+cntPt[0]\n",
    "    yMid = (parentPt[1]-cntPt[1])/2+cntPt[1]\n",
    "    createPlot.ax1.text(xMid,yMid,txtString)\n",
    "\n",
    "def plotTree(myTree,parentPt,nodeTxt):\n",
    "    \"\"\"绘制树形图\"\"\"\n",
    "    numLeafs = getNumLeafs(myTree)\n",
    "    depth = getTreeDepth(myTree)\n",
    "    firstStr = list(myTree.keys())[0]\n",
    "    cntrPt = (plotTree.xOff + (1 + float(numLeafs))/2/plotTree.totalW,plotTree.yOff)\n",
    "    plotMidText(cntrPt,parentPt,nodeTxt)\n",
    "    plotNode(firstStr,cntrPt,parentPt,decisionNode)\n",
    "    secondDict = myTree[firstStr]\n",
    "    plotTree.yOff = plotTree.yOff-1/plotTree.totalD\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__=='dict':\n",
    "            plotTree(secondDict[key],cntrPt,str(key))\n",
    "        else:\n",
    "            plotTree.xOff = plotTree.xOff + 1/plotTree.totalW\n",
    "            plotNode(secondDict[key],(plotTree.xOff,plotTree.yOff),cntrPt,leafNode)\n",
    "            plotMidText((plotTree.xOff,plotTree.yOff),cntrPt,str(key))\n",
    "    plotTree.yOff = plotTree.yOff + 1 / plotTree.totalD\n",
    "\n",
    "def createPlot(inTree):\n",
    "    \"\"\"创建绘图区\"\"\"\n",
    "    fig = plt.figure(1,facecolor='white')\n",
    "    fig.clf()\n",
    "    axprops = dict(xticks=[],yticks=[])\n",
    "    createPlot.ax1 = plt.subplot(111,frameon=False,**axprops)\n",
    "    plotTree.totalW = float(getNumLeafs(inTree))\n",
    "    plotTree.totalD = float(getTreeDepth(inTree))\n",
    "    plotTree.xOff = -0.5/plotTree.totalW\n",
    "    plotTree.yOff = 1.0\n",
    "    plotTree(inTree,(0.5,1.0),'')\n",
    "    plt.show()\n",
    "\n",
    "def classify(inputTree,featLabels,testVec):\n",
    "    \"\"\"使用决策树的分类函数\"\"\"\n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex]==key:\n",
    "            if type(secondDict[key]).__name__ == 'dict':\n",
    "                classLabel = classify(secondDict[key],featLabels,testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel\n",
    "def lenses_test():\n",
    "    \"\"\"使用决策树预测隐形眼镜类型\"\"\"\n",
    "    fr = open('../adult.data')\n",
    "    lenses = [inst.strip().split('  ') for inst in fr.readlines()]\n",
    "#     lensesLabel = ['age','prescript','astigmatic','tearRate']\n",
    "    lensesLabel = ['>=50K','<50K']\n",
    "    lensesTree = createTree(lenses,lensesLabel)  # 创建树\n",
    "    print(lensesTree)\n",
    "    createPlot(lensesTree)  # 绘制树\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    decisionNode = dict(boxstyle='sawtooth',fc='0.8')\n",
    "    leafNode = dict(boxstyle='round4',fc='0.8')\n",
    "    arrow_args = dict(arrowstyle='<-')\n",
    "    lenses_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91a481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbbd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator\n",
    "import numpy as np\n",
    "\n",
    "def createDataSet():\n",
    "    \"\"\"构建数据集\"\"\"\n",
    "    dataSet = [['是', '单身', 125, '否'],\n",
    "               ['否', '已婚', 100, '否'],\n",
    "               ['否', '单身', 70, '否'],\n",
    "               ['是', '已婚', 120, '否'],\n",
    "               ['否', '离异', 95, '是'],\n",
    "               ['否', '已婚', 60, '否'],\n",
    "               ['是', '离异', 220, '否'],\n",
    "               ['否', '单身', 85, '是'],\n",
    "               ['否', '已婚', 75, '否'],\n",
    "               ['否', '单身', 90, '是']]\n",
    "    labels = ['是否有房', '婚姻状况', '年收入(k)']  # 三个特征\n",
    "    return dataSet, labels\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    \"\"\"\n",
    "    计算给定数据集的香农熵\n",
    "    :param dataSet:给定的数据集\n",
    "    :return:返回香农熵\n",
    "    \"\"\"\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts ={}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] =0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for label in labelCounts.keys():\n",
    "        prob = float(labelCounts[label])/numEntries\n",
    "        shannonEnt -= prob*log(prob,2)\n",
    "    return shannonEnt\n",
    "\n",
    "def majorityCnt(classList):\n",
    "    \"\"\"获取出现次数最好的分类名称\"\"\"\n",
    "    classCount = {}\n",
    "    classList= np.mat(classList).flatten().A.tolist()[0]  # 数据为[['否'], ['是'], ['是']], 转换后为['否', '是', '是']\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "def splitDataSet(dataSet,axis,value):\n",
    "    \"\"\"对离散型特征划分数据集\"\"\"\n",
    "    retDataSet = []  # 创建新的list对象，作为返回的数据\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])  # 抽取\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "\n",
    "\n",
    "def splitContinuousDataSet(dataSet, axis, value, direction):\n",
    "    \"\"\"对连续型特征划分数据集\"\"\"\n",
    "    subDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if direction == 0:\n",
    "            if featVec[axis] > value:  # 按照大于(>)该值进行划分\n",
    "                reduceData = featVec[:axis]\n",
    "                reduceData.extend(featVec[axis + 1:])\n",
    "                subDataSet.append(reduceData)\n",
    "        if direction == 1:\n",
    "            if featVec[axis] <= value:  # 按照小于等于(<=)该值进行划分\n",
    "                reduceData = featVec[:axis]\n",
    "                reduceData.extend(featVec[axis + 1:])\n",
    "                subDataSet.append(reduceData)\n",
    "    return subDataSet\n",
    "\n",
    "def chooseBestFeatureToSplit(dataSet, labels):\n",
    "    \"\"\"选择最好的数据集划分方式\"\"\"\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    baseGainRatio = 0.0\n",
    "    bestFeature = -1\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    # 建立一个字典，用来存储每一个连续型特征所对应最佳切分点的具体值\n",
    "    bestSplitDic = {}\n",
    "    # print('dataSet[0]:' + str(dataSet[0]))\n",
    "    for i in range(numFeatures):\n",
    "        # 获取第i个特征的特征值\n",
    "        featVals = [example[i] for example in dataSet]\n",
    "        # 如果该特征时连续型数据\n",
    "        if type(featVals[0]).__name__ == 'float' or type(\n",
    "                featVals[0]).__name__ == 'int':\n",
    "            # 将该特征的所有值按从小到大顺序排序\n",
    "            sortedFeatVals = sorted(featVals)\n",
    "            # 取相邻两样本值的平均数做划分点，共有 len(featVals)-1 个\n",
    "            splitList = []\n",
    "            for j in range(len(featVals) - 1):\n",
    "                splitList.append(\n",
    "                    (sortedFeatVals[j] + sortedFeatVals[j + 1]) / 2.0)\n",
    "            # 遍历每一个切分点\n",
    "            for j in range(len(splitList)):\n",
    "                # 计算该划分方式的条件信息熵newEntropy\n",
    "                newEntropy = 0.0\n",
    "                value = splitList[j]\n",
    "                # 将数据集划分为两个子集\n",
    "                greaterSubDataSet = splitContinuousDataSet(dataSet, i, value, 0)\n",
    "                smallSubDataSet = splitContinuousDataSet(dataSet, i, value, 1)\n",
    "                prob0 = len(greaterSubDataSet) / float(len(dataSet))\n",
    "                newEntropy += prob0 * calcShannonEnt(greaterSubDataSet)\n",
    "                prob1 = len(smallSubDataSet) / float(len(dataSet))\n",
    "                newEntropy += prob1 * calcShannonEnt(smallSubDataSet)\n",
    "                # 计算该划分方式的分裂信息\n",
    "                splitInfo = 0.0\n",
    "                splitInfo -= prob0 * log(prob0, 2)\n",
    "                splitInfo -= prob1 * log(prob1, 2)\n",
    "                # 计算信息增益率 = 信息增益 / 该划分方式的分裂信息\n",
    "                gainRatio = float(baseEntropy - newEntropy) / splitInfo\n",
    "                if gainRatio > baseGainRatio:\n",
    "                    baseGainRatio = gainRatio\n",
    "                    bestSplit = j\n",
    "                    bestFeature = i\n",
    "            bestSplitDic[labels[i]] = splitList[bestSplit]  # 最佳切分点\n",
    "        else:  # 如果该特征时连续型数据\n",
    "            uniqueVals = set(featVals)\n",
    "            splitInfo = 0.0\n",
    "            # 计算每种划分方式的条件信息熵newEntropy\n",
    "            newEntropy = 0.0\n",
    "            for value in uniqueVals:\n",
    "                subDataSet = splitDataSet(dataSet, i, value)\n",
    "                prob = len(subDataSet)/float(len(dataSet))\n",
    "                splitInfo -= prob * log(prob, 2)  # 计算分裂信息\n",
    "                newEntropy += prob * calcShannonEnt(subDataSet)  # 计算条件信息熵\n",
    "            # 若该特征的特征值都相同，说明信息增益和分裂信息都为0，则跳过该特征\n",
    "            if splitInfo == 0.0:\n",
    "                continue\n",
    "            # 计算信息增益率 = 信息增益 / 该划分方式的分裂信息\n",
    "            gainRatio = float(baseEntropy - newEntropy) / splitInfo\n",
    "            if gainRatio > baseGainRatio:\n",
    "                bestFeature = i\n",
    "                baseGainRatio = gainRatio\n",
    "    # 如果最佳切分特征是连续型，则最佳切分点为具体的切分值\n",
    "    if type(dataSet[0][bestFeature]).__name__ == 'float' or type(\n",
    "            dataSet[0][bestFeature]).__name__ == 'int':\n",
    "        bestFeatValue = bestSplitDic[labels[bestFeature]]\n",
    "    # 如果最佳切分特征时离散型，则最佳切分点为 切分特征名称,【其实对于离散型特征这个值没有用】\n",
    "    if type(dataSet[0][bestFeature]).__name__ == 'str':\n",
    "        bestFeatValue = labels[bestFeature]\n",
    "    # print('bestFeature:' + str(labels[bestFeature]) + ', bestFeatValue:' + str(bestFeatValue))\n",
    "    return bestFeature, bestFeatValue\n",
    "\n",
    "\n",
    "def createTree(dataSet, labels):\n",
    "    \"\"\"创建C4.5树\"\"\"\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    # 如果类别完全相同，则停止继续划分\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    # 遍历完所有特征时返回出现次数最多的类别\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "    bestFeature, bestFeatValue = chooseBestFeatureToSplit(dataSet, labels)\n",
    "    if bestFeature == -1:  # 如果无法选出最优分类特征，返回出现次数最多的类别\n",
    "        return majorityCnt(classList)\n",
    "    bestFeatLabel = labels[bestFeature]\n",
    "    myTree = {bestFeatLabel: {}}\n",
    "    subLabels = labels[:bestFeature]\n",
    "    subLabels.extend(labels[bestFeature + 1:])\n",
    "    # 针对最佳切分特征是离散型\n",
    "    if type(dataSet[0][bestFeature]).__name__ == 'str':\n",
    "        featVals = [example[bestFeature] for example in dataSet]\n",
    "        uniqueVals = set(featVals)\n",
    "        for value in uniqueVals:\n",
    "            reduceDataSet = splitDataSet(dataSet, bestFeature, value)\n",
    "            # print('reduceDataSet:' + str(reduceDataSet))\n",
    "            myTree[bestFeatLabel][value] = createTree(reduceDataSet, subLabels)\n",
    "            # print(myTree[bestFeatLabel][value])\n",
    "    # 针对最佳切分特征是连续型\n",
    "    if type(dataSet[0][bestFeature]).__name__ == 'int' or type(\n",
    "            dataSet[0][bestFeature]).__name__ == 'float':\n",
    "        # 将数据集划分为两个子集，针对每个子集分别建树\n",
    "        value = bestFeatValue\n",
    "        greaterSubDataSet = splitContinuousDataSet(dataSet, bestFeature, value, 0)\n",
    "        smallSubDataSet = splitContinuousDataSet(dataSet, bestFeature, value, 1)\n",
    "        # print('greaterDataset:' + str(greaterSubDataSet))\n",
    "        # print('smallerDataSet:' + str(smallSubDataSet))\n",
    "        # 针对连续型特征，在生成决策的模块，修改划分点的标签，如“> x.xxx”，\"<= x.xxx\"\n",
    "        myTree[bestFeatLabel]['>' + str(value)] = createTree(greaterSubDataSet,subLabels)\n",
    "        myTree[bestFeatLabel]['<=' + str(value)] = createTree(smallSubDataSet,subLabels)\n",
    "    return myTree\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataSet, labels = createDataSet()\n",
    "    mytree = createTree(dataSet, labels)\n",
    "    print(\"最终构建的C4.5分类树为：\\n\",mytree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
