{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5581729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<=50K\n",
      "dict_keys([])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'<=50K'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14568/843410780.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[0mlabelList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m \u001b[0mTree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreateTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabelList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[0msum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14568/843410780.py\u001b[0m in \u001b[0;36mcreateTree\u001b[1;34m(dataSet, labels)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#如果划分数据集已经到了无法继续划分的程度，即已经使用完了全部的feature，则进行决策\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmajority\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassificationList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[0mbestFeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchooseBestSplitWay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#计算香农熵和信息增益来返回最佳的划分方案，bestFeature保存最佳的划分的feature的索引\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[0mbestFeatureLabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbestFeature\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#取出上述的bestfeature的具体值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[0mTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mbestFeatureLabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14568/843410780.py\u001b[0m in \u001b[0;36mchooseBestSplitWay\u001b[1;34m(dataSet)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;31m#选择最好的数据集划分方式\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchooseBestSplitWay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mHC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculateEntropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#计算整个数据集的香农熵(期望信息)，即H(C)，用来和每个feature的香农熵进行比较\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[0mbestfeatureIndex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m                   \u001b[1;31m#最好的划分方式的索引值，因为0也是索引值，所以应该设置为负数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mgain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m                        \u001b[1;31m#信息增益=期望信息-熵，gain为最好的信息增益，IG为各种划分方式的信息增益\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14568/843410780.py\u001b[0m in \u001b[0;36mcalculateEntropy\u001b[1;34m(dataSet)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasification\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mClassifyCount\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasification\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mClassifyCount\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasification\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m         \u001b[1;31m#计算出现次数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mshannonEntropy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mClassifyCount\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '<=50K'"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "from math import log\n",
    "import operator\n",
    "import pickle\n",
    "\n",
    "#读取数据集\n",
    "def createDateset(filename):\n",
    "    with open(filename, 'r')as csvfile:\n",
    "        dataset= [line.strip().split(', ') for line in csvfile.readlines()]     #读取文件中的每一行\n",
    "        dataset=[[int(i) if i.isdigit() else i for i in row] for row in dataset]    #对于每一行中的每一个元素，将行列式数字化并且去除空白保证匹配的正确完成\n",
    "        cleanoutdata(dataset)   #清洗数据\n",
    "        del (dataset[-1])       #去除最后一行的空行\n",
    "        precondition(dataset)   #预处理数据\n",
    "        labels=['workclass','education',\n",
    "               'marital-status','occupation',\n",
    "                'relationship','race','sex',\n",
    "                'native-country']\n",
    "        return dataset,labels\n",
    "\n",
    "def cleanoutdata(dataset):#数据清洗\n",
    "    for row in dataset:\n",
    "        for column in row:\n",
    "            if column == '?' or column=='':\n",
    "                dataset.remove(row)\n",
    "                break\n",
    "\n",
    "#计算香农熵/期望信息\n",
    "def calculateEntropy(dataSet):\n",
    "    ClassifyCount = {}#分类标签统计字典，用来统计每个分类标签的概率\n",
    "    for vector in dataSet:\n",
    "        clasification = vector[-1]  #获取分类\n",
    "        print(clasification)\n",
    "        print(ClassifyCount.keys())\n",
    "        if not clasification not in ClassifyCount.keys():#如果分类暂时不在字典中，在字典中添加对应的值对\n",
    "            print(clasification)\n",
    "            ClassifyCount[clasification] = 0\n",
    "        ClassifyCount[clasification] += 1         #计算出现次数\n",
    "    shannonEntropy=0.0\n",
    "    for key in ClassifyCount:\n",
    "        probability=float(ClassifyCount[key]) / dataSet.shape[0]      #计算概率\n",
    "        shannonEntropy -= probability * log(probability,2)   #香农熵的每一个子项都是负的\n",
    "    return shannonEntropy\n",
    "\n",
    "# def addFetureValue(feature):\n",
    "\n",
    "#划分数据集\n",
    "def splitDataSet(dataSet,featureIndex,value):\n",
    "    newDataSet=[]\n",
    "    for vec in dataSet:#将选定的feature的列从数据集中去除\n",
    "        if vec[featureIndex] == value:\n",
    "            rest = vec[:featureIndex]\n",
    "            rest.extend(vec[featureIndex + 1:])\n",
    "            newDataSet.append(rest)\n",
    "    return newDataSet\n",
    "\n",
    "\n",
    "def addFeatureValue(featureListOfValue,feature):\n",
    "    feat = [[ 'Private', 'Self-emp-not-inc', 'Self-emp-inc',\n",
    "              'Federal-gov', 'Local-gov', 'State-gov', 'Without-pay', 'Never-worked'],\n",
    "            [],[],[],[],[]]\n",
    "    for featureValue in feat[feature]: #feat保存的是所有属性特征的所有可能的取值，其结构为feat = [ [val1,val2,val3,…,valn], [], [], [], … ,[] ]\n",
    "        featureListOfValue.append(featureValue)\n",
    "\n",
    "#选择最好的数据集划分方式\n",
    "def chooseBestSplitWay(dataSet):\n",
    "    HC = calculateEntropy(dataSet)#计算整个数据集的香农熵(期望信息)，即H(C)，用来和每个feature的香农熵进行比较\n",
    "    bestfeatureIndex = -1                   #最好的划分方式的索引值，因为0也是索引值，所以应该设置为负数\n",
    "    gain=0.0                        #信息增益=期望信息-熵，gain为最好的信息增益，IG为各种划分方式的信息增益\n",
    "    for feature in range(len(dataSet[0]) -1 ): #计算feature的个数，由于dataset中是包含有类别的，所以要减去类别\n",
    "        featureListOfValue=[vector[feature] for vector in dataSet] #对于dataset中每一个feature，创建单独的列表list保存其取值，其中是不重复的\n",
    "        addFeatureValue(featureListOfValue,feature) #增加在训练集中有，测试集中没有的属性特征的取值\n",
    "        unique=set(featureListOfValue)\n",
    "        HTC=0.0         #保存HTC，即H（T|C）\n",
    "        for value in unique:\n",
    "            subDataSet = splitDataSet(dataSet,feature,value)  #划分数据集\n",
    "            probability = len(subDataSet) / float(len(dataSet))  #求得当前类别的概率\n",
    "            HTC += probability * calculateEntropy(subDataSet)      #计算当前类别的香农熵，并和HTC想加，即H(T|C) = H（T1|C）+ H(T2|C) + … + H(TN|C)\n",
    "        IG=HC-HTC        #计算对于该种划分方式的信息增益\n",
    "        if(IG > gain):\n",
    "            gain = IG\n",
    "            bestfeatureIndex = feature\n",
    "    return bestfeatureIndex\n",
    "\n",
    "#返回出现次数最多的类别，避免产生所有特征全部用完无法判断类别的情况\n",
    "def majority(classList):\n",
    "    classificationCount = {}\n",
    "    for i in classList:\n",
    "        if not i in classificationCount.keys():\n",
    "            classificationCount[i] = 0\n",
    "        classificationCount[i] += 1\n",
    "    sortedClassification = sorted(dict2list(classificationCount),key = operator.itemgetter(1),reverse = True)\n",
    "    return sortedClassification[0][0]\n",
    "\n",
    "#dict字典转换为list列表\n",
    "def dict2list(dic:dict):\n",
    "    keys=dic.keys()\n",
    "    values=dic.values()\n",
    "    lst=[(key,value)for key,value in zip(keys,values)]\n",
    "    return lst\n",
    "\n",
    "#创建树\n",
    "def createTree(dataSet,labels):\n",
    "    classificationList = [feature[-1] for feature in dataSet] #产生数据集中的分类列表，保存的是每一行的分类\n",
    "    if classificationList.count(classificationList[0]) == len(classificationList): #如果分类别表中的所有分类都是一样的，则直接返回当前的分类\n",
    "        return classificationList[0]\n",
    "    if len(dataSet[0]) == 1: #如果划分数据集已经到了无法继续划分的程度，即已经使用完了全部的feature，则进行决策\n",
    "        return majority(classificationList)\n",
    "    bestFeature = chooseBestSplitWay(dataSet) #计算香农熵和信息增益来返回最佳的划分方案，bestFeature保存最佳的划分的feature的索引\n",
    "    bestFeatureLabel = labels[bestFeature] #取出上述的bestfeature的具体值\n",
    "    Tree = {bestFeatureLabel:{}}\n",
    "    del(labels[bestFeature]) #删除当前进行划分是使用的feature避免下次继续使用到这个feature来划分\n",
    "    featureValueList = [feature[bestFeature]for feature in dataSet] #对于上述取出的bestFeature,取出数据集中属于当前feature的列的所有的值\n",
    "    uniqueValue = set(featureValueList) #去重\n",
    "    for value in uniqueValue: #对于每一个feature标签的value值，进行递归构造决策树\n",
    "        subLabels = labels[:]\n",
    "        Tree[bestFeatureLabel][value] = createTree(splitDataSet(dataSet,bestFeature,value),subLabels)\n",
    "    return Tree\n",
    "\n",
    "def storeTree(inputree,filename):\n",
    "    fw = open(filename, 'wb')\n",
    "    pickle.dump(inputree, fw)\n",
    "    fw.close()\n",
    "\n",
    "def grabTree(filename):\n",
    "    fr = open(filename, 'rb')\n",
    "    return pickle.load(fr)\n",
    "\n",
    "#测试算法\n",
    "def classify(inputTree,featLabels,testVector):\n",
    "    root = list(inputTree.keys())[0] #取出树的第一个标签,即树的根节点\n",
    "    dictionary = inputTree[root] #取出树的第一个标签下的字典\n",
    "    featIndex = featLabels.index(root)\n",
    "    for key in dictionary.keys():#对于这个字典\n",
    "        if testVector[featIndex] == key:\n",
    "            if type(dictionary[key]).__name__ == 'dict': #如果还有一个新的字典\n",
    "                classLabel = classify(dictionary[key],featLabels,testVector)#递归向下寻找到非字典的情况，此时是叶子节点，叶子节点保存的肯定是类别\n",
    "            else:\n",
    "                classLabel=dictionary[key]#叶子节点，返回类别\n",
    "    return classLabel\n",
    "\n",
    "def test(mytree,labels,filename,sum,correct,error):\n",
    "    with open(filename, 'r')as csvfile:\n",
    "        dataset=[line.strip().split(', ') for line in csvfile.readlines()]     #读取文件中的每一行\n",
    "        dataset=[[int(i) if i.isdigit() else i for i in row] for row in dataset]    #对于每一行中的每一个元素，将行列式数字化并且去除空白保证匹配的正确完成\n",
    "        cleanoutdata(dataset)   #数据清洗\n",
    "        del(dataset[0])         #删除第一行和最后一行的空白数据\n",
    "        del(dataset[-1])\n",
    "        precondition(dataset)       #预处理数据集\n",
    "        # clean(dataset)          #把测试集中的，不存在于训练集中的数据清洗掉\n",
    "        sum = len(dataset)\n",
    "    for line in dataset:\n",
    "        result=classify(mytree,labels,line)+'.'\n",
    "        if result==line[8]:     #如果测试结果和类别相同\n",
    "            correct = correct + 1\n",
    "        else :\n",
    "            error = error + 1\n",
    "\n",
    "    return sum,correct,error\n",
    "\n",
    "def precondition(mydate):#清洗连续型数据\n",
    "    #continuous:0,2,4,10,11,12\n",
    "    for each in mydate:\n",
    "        del(each[0])\n",
    "        del(each[1])\n",
    "        del(each[2])\n",
    "        del(each[7])\n",
    "        del(each[7])\n",
    "        del(each[7])\n",
    "\n",
    "# def clean(dataset):#清洗掉测试集中出现了训练集中没有的值的情况\n",
    "#     global mydate\n",
    "#     for i in range(8):\n",
    "#         set1=set()\n",
    "#         for row1 in mydate:\n",
    "#             set1.add(row1[i])\n",
    "#         for row2 in dataset:\n",
    "#             if row2[i] not in set1:\n",
    "#                dataset.remove(row2)\n",
    "#         set1.clear()\n",
    "\n",
    "dataSetName=r\"adult.data\"\n",
    "mydate,label=createDateset(dataSetName)\n",
    "labelList=label[:]\n",
    "\n",
    "Tree=createTree(mydate,labelList)\n",
    "\n",
    "sum = 0\n",
    "correct = 0\n",
    "error = 0\n",
    "\n",
    "storeTree(Tree,r'C:\\Users\\idsl\\Desktop\\dt\\tree.txt') #保存决策树，避免下次再生成决策树\n",
    "\n",
    "# Tree=grabTree(r'C:\\Users\\yang\\Desktop\\tree.txt')#读取决策树，如果已经存在tree.txt可以直接使用决策树不需要再次生成决策树\n",
    "sum,current,unreco=test(Tree,label,r'adult.test',sum,correct,error)\n",
    "# with open(r'C:\\Users\\yang\\Desktop\\trees.txt', 'w')as f:\n",
    "#     f.write(str(Tree))\n",
    "print(\"准确率：%f\" % correct / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5352d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 原始資料長度\n",
    "print(f'training_data：{len(training_data)} records')\n",
    "print(f'test_data：{len(test_data)} records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b14529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 命名欄位\n",
    "training_data.columns = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','label']\n",
    "test_data.columns = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','label']\n",
    "feature_cols = ['age','workclass','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country']\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f55dc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in training_data.columns:\n",
    "    print(training_data[column].value_counts())\n",
    "    \n",
    "## education跟education-num數量一樣所以取education-num即可，故刪除education\n",
    "training_data = training_data.drop(columns=['education'])\n",
    "test_data = test_data.drop(columns=['education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c8988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training_data['age']=training_data['age'].astype('object')\n",
    "# test_data['age']=test_data['age'].astype('object')\n",
    "# for row in range(len(training_data['age'])):\n",
    "#     print(row)\n",
    "#     age=int(training_data['age'][row])\n",
    "#     if age<19: test_data['age'][row]=training_data['age'][row]='teen'\n",
    "#     elif age<41:  test_data['age'][row]=training_data['age'][row]='adult'\n",
    "#     elif age<81:  test_data['age'][row]=training_data['age'][row]='old-adult'\n",
    "#     elif age<100:  test_data['age'][row]=training_data['age'][row]='elder'\n",
    "convert = {\"label\" :{\"<=50K\":0, \">50K\":1}}\n",
    "training_data = training_data.replace(convert)\n",
    "convert = {\"label\" :{\"<=50K.\":0, \">50K.\":1}}\n",
    "test_data = test_data.replace(convert)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e7fd32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee65fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失值數量\n",
    "print(\"=======training_data=======\")\n",
    "for col,cnt in zip(training_data.columns,(training_data=='?').sum(axis = 0)):\n",
    "    if cnt > 0:\n",
    "        print(str(col) + ': ' + str(cnt) + ' records has missing value')\n",
    "        \n",
    "\n",
    "print(\"=======test_data=======\")\n",
    "for col,cnt in zip(test_data.columns,(test_data=='?').sum(axis = 0)):\n",
    "    if cnt > 0:\n",
    "        print(str(col) + ': ' + str(cnt) + ' records has missing value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82758ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data[training_data['workclass']!='?']       \n",
    "training_data = training_data[training_data['occupation']!='?']      \n",
    "training_data = training_data[training_data['native-country']!='?']   \n",
    "\n",
    "test_data = test_data[test_data['workclass']!='?']       \n",
    "test_data = test_data[test_data['occupation']!='?']      \n",
    "test_data = test_data[test_data['native-country']!='?']   \n",
    "\n",
    "# ## 刪除缺失值後資料長度\n",
    "# print(f'training_data：{len(training_data)} records')\n",
    "# print(f'test_data：{len(test_data)} records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1da8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data.replace('?', 'other', inplace=True)\n",
    "# test_data.replace('?', 'other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb53ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 確認無缺失值\n",
    "print(\"=======training_data=======\")\n",
    "for col,cnt in zip(training_data.columns,(training_data=='?').sum(axis = 1)):\n",
    "    if cnt == 0:\n",
    "        print(str(col) + ': ' + str(cnt) + ' records')\n",
    "        \n",
    "        \n",
    "print(\"=======test_data=======\")    \n",
    "for col,cnt in zip(test_data.columns,(test_data=='?').sum(axis = 1)):\n",
    "    if cnt == 0:\n",
    "        print(str(col) + ': ' + str(cnt) + ' records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c0802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data = pd.get_dummies(training_data)\n",
    "test_data = pd.get_dummies(test_data)\n",
    "feature_cols = training_data.columns\n",
    "# print(*feature_cols,sep='\\n')\n",
    "training_data['label'] = training_data['label'].astype('int64')\n",
    "test_data['label'] = test_data['label'].astype('int64')\n",
    "for column in training_data.columns:\n",
    "    if column not in test_data.columns:\n",
    "        test_data[column] = 0\n",
    "        print(training_data[column])\n",
    "        print(test_data[column])\n",
    "        break\n",
    "print(training_data.info())\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1974c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data.drop('label',axis=1)\n",
    "X = X.drop('fnlwgt',axis=1)\n",
    "y = training_data['label']\n",
    "# print(Xt.columns)\n",
    "Xt = test_data.drop('label',axis=1)\n",
    "Xt = Xt.drop('fnlwgt',axis=1)\n",
    "# Xt.columns has 87 columns but X.columns has 88 columns\n",
    "Xt.columns = X.columns\n",
    "yt = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c642ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X.columns))\n",
    "print(len(Xt.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3cea96e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6033\n",
      "6033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42) # 80% training and 20% test\n",
    "xx_train, xx_test, yy_train, yy_test = train_test_split(Xt, yt, test_size=0.2,random_state=42) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "513d0261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7463948284435604, 0.8271175203049892, 0.8423669816011934, 0.8431957566716393, 0.8461793469252444, 0.8524780374606332, 0.8544670976297033, 0.8584452179678436, 0.856124647770595, 0.8571191778551301, 0.8582794629537543, 0.8584452179678436, 0.8581137079396651, 0.8566219128128626, 0.8562904027846843, 0.8552958727001492, 0.8569534228410409, 0.8569534228410409]\n",
      "[0.7463948284435604, 0.6671639317089342, 0.6590419360185645, 0.6572186308635837, 0.6597049560749213, 0.6477705950605006, 0.6442897397646279, 0.6476048400464114, 0.649096635173214, 0.6539035305818001, 0.6527432454831759, 0.6527432454831759, 0.6530747555113542, 0.6522459804409083, 0.6451185148350738, 0.629371788496602, 0.6323553787502072, 0.6323553787502072]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "ax = []\n",
    "a_train = []\n",
    "a_test = []\n",
    "for depth in range(1,19):\n",
    "    ax.append(depth)\n",
    "    dt = DecisionTreeClassifier(criterion='gini',max_depth=depth, max_leaf_nodes = 76)\n",
    "    dt.fit(X_train,y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    a_train.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    yy_pred = dt.predict(Xt)\n",
    "    a_test.append(metrics.accuracy_score(y_test, yy_pred))\n",
    "    \n",
    "print(a_train)\n",
    "plt.plot(ax, a_train,label='train')\n",
    "print(a_test)\n",
    "plt.plot(ax, a_test,label='test')\n",
    "plt.xticks(ax)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "851a8c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "yy_pred = clf.predict(Xt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94677aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8176694845019061\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6033, 15060]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18620/2449706544.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[1;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multilabel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y_true\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y_pred\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    398\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6033, 15060]"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, yy_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bceab161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30162 entries, 0 to 32560\n",
      "Data columns (total 87 columns):\n",
      " #   Column                                     Non-Null Count  Dtype\n",
      "---  ------                                     --------------  -----\n",
      " 0   age                                        30162 non-null  int64\n",
      " 1   education-num                              30162 non-null  int64\n",
      " 2   capital-gain                               30162 non-null  int64\n",
      " 3   capital-loss                               30162 non-null  int64\n",
      " 4   hours-per-week                             30162 non-null  int64\n",
      " 5   workclass_Federal-gov                      30162 non-null  uint8\n",
      " 6   workclass_Local-gov                        30162 non-null  uint8\n",
      " 7   workclass_Private                          30162 non-null  uint8\n",
      " 8   workclass_Self-emp-inc                     30162 non-null  uint8\n",
      " 9   workclass_Self-emp-not-inc                 30162 non-null  uint8\n",
      " 10  workclass_State-gov                        30162 non-null  uint8\n",
      " 11  workclass_Without-pay                      30162 non-null  uint8\n",
      " 12  marital-status_Divorced                    30162 non-null  uint8\n",
      " 13  marital-status_Married-AF-spouse           30162 non-null  uint8\n",
      " 14  marital-status_Married-civ-spouse          30162 non-null  uint8\n",
      " 15  marital-status_Married-spouse-absent       30162 non-null  uint8\n",
      " 16  marital-status_Never-married               30162 non-null  uint8\n",
      " 17  marital-status_Separated                   30162 non-null  uint8\n",
      " 18  marital-status_Widowed                     30162 non-null  uint8\n",
      " 19  occupation_Adm-clerical                    30162 non-null  uint8\n",
      " 20  occupation_Armed-Forces                    30162 non-null  uint8\n",
      " 21  occupation_Craft-repair                    30162 non-null  uint8\n",
      " 22  occupation_Exec-managerial                 30162 non-null  uint8\n",
      " 23  occupation_Farming-fishing                 30162 non-null  uint8\n",
      " 24  occupation_Handlers-cleaners               30162 non-null  uint8\n",
      " 25  occupation_Machine-op-inspct               30162 non-null  uint8\n",
      " 26  occupation_Other-service                   30162 non-null  uint8\n",
      " 27  occupation_Priv-house-serv                 30162 non-null  uint8\n",
      " 28  occupation_Prof-specialty                  30162 non-null  uint8\n",
      " 29  occupation_Protective-serv                 30162 non-null  uint8\n",
      " 30  occupation_Sales                           30162 non-null  uint8\n",
      " 31  occupation_Tech-support                    30162 non-null  uint8\n",
      " 32  occupation_Transport-moving                30162 non-null  uint8\n",
      " 33  relationship_Husband                       30162 non-null  uint8\n",
      " 34  relationship_Not-in-family                 30162 non-null  uint8\n",
      " 35  relationship_Other-relative                30162 non-null  uint8\n",
      " 36  relationship_Own-child                     30162 non-null  uint8\n",
      " 37  relationship_Unmarried                     30162 non-null  uint8\n",
      " 38  relationship_Wife                          30162 non-null  uint8\n",
      " 39  race_Amer-Indian-Eskimo                    30162 non-null  uint8\n",
      " 40  race_Asian-Pac-Islander                    30162 non-null  uint8\n",
      " 41  race_Black                                 30162 non-null  uint8\n",
      " 42  race_Other                                 30162 non-null  uint8\n",
      " 43  race_White                                 30162 non-null  uint8\n",
      " 44  sex_Female                                 30162 non-null  uint8\n",
      " 45  sex_Male                                   30162 non-null  uint8\n",
      " 46  native-country_Cambodia                    30162 non-null  uint8\n",
      " 47  native-country_Canada                      30162 non-null  uint8\n",
      " 48  native-country_China                       30162 non-null  uint8\n",
      " 49  native-country_Columbia                    30162 non-null  uint8\n",
      " 50  native-country_Cuba                        30162 non-null  uint8\n",
      " 51  native-country_Dominican-Republic          30162 non-null  uint8\n",
      " 52  native-country_Ecuador                     30162 non-null  uint8\n",
      " 53  native-country_El-Salvador                 30162 non-null  uint8\n",
      " 54  native-country_England                     30162 non-null  uint8\n",
      " 55  native-country_France                      30162 non-null  uint8\n",
      " 56  native-country_Germany                     30162 non-null  uint8\n",
      " 57  native-country_Greece                      30162 non-null  uint8\n",
      " 58  native-country_Guatemala                   30162 non-null  uint8\n",
      " 59  native-country_Haiti                       30162 non-null  uint8\n",
      " 60  native-country_Holand-Netherlands          30162 non-null  uint8\n",
      " 61  native-country_Honduras                    30162 non-null  uint8\n",
      " 62  native-country_Hong                        30162 non-null  uint8\n",
      " 63  native-country_Hungary                     30162 non-null  uint8\n",
      " 64  native-country_India                       30162 non-null  uint8\n",
      " 65  native-country_Iran                        30162 non-null  uint8\n",
      " 66  native-country_Ireland                     30162 non-null  uint8\n",
      " 67  native-country_Italy                       30162 non-null  uint8\n",
      " 68  native-country_Jamaica                     30162 non-null  uint8\n",
      " 69  native-country_Japan                       30162 non-null  uint8\n",
      " 70  native-country_Laos                        30162 non-null  uint8\n",
      " 71  native-country_Mexico                      30162 non-null  uint8\n",
      " 72  native-country_Nicaragua                   30162 non-null  uint8\n",
      " 73  native-country_Outlying-US(Guam-USVI-etc)  30162 non-null  uint8\n",
      " 74  native-country_Peru                        30162 non-null  uint8\n",
      " 75  native-country_Philippines                 30162 non-null  uint8\n",
      " 76  native-country_Poland                      30162 non-null  uint8\n",
      " 77  native-country_Portugal                    30162 non-null  uint8\n",
      " 78  native-country_Puerto-Rico                 30162 non-null  uint8\n",
      " 79  native-country_Scotland                    30162 non-null  uint8\n",
      " 80  native-country_South                       30162 non-null  uint8\n",
      " 81  native-country_Taiwan                      30162 non-null  uint8\n",
      " 82  native-country_Thailand                    30162 non-null  uint8\n",
      " 83  native-country_Trinadad&Tobago             30162 non-null  uint8\n",
      " 84  native-country_United-States               30162 non-null  uint8\n",
      " 85  native-country_Vietnam                     30162 non-null  uint8\n",
      " 86  native-country_Yugoslavia                  30162 non-null  uint8\n",
      "dtypes: int64(5), uint8(82)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()\n",
    "# y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d8885668",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "Program terminated with status: 1. stderr follows: Error: not well-formed (invalid token) in line 1 \r\n... <HTML>native-country_Trinadad&Tobago &le; 0.5 ...\r\nin label of node 2031\r\nError: not well-formed (invalid token) in line 1 \r\n... <HTML>native-country_Trinadad&Tobago &le; 0.5 ...\r\nin label of node 6622\r\ndot: graph is too large for cairo-renderer bitmaps. Scaling by 0.238349 to fit\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18620/1791728047.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                 special_characters=True,feature_names = X.columns,class_names=['0','1'])\n\u001b[0;32m      9\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'diabetes.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(path, f, prog)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[1;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1810\u001b[1;33m                 \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m             )\n\u001b[0;32m   1812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m                 \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   2028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2030\u001b[1;33m             raise InvocationException(\n\u001b[0m\u001b[0;32m   2031\u001b[0m                 'Program terminated with status: %d. stderr follows: %s' % (\n\u001b[0;32m   2032\u001b[0m                     status, stderr_output))\n",
      "\u001b[1;31mInvocationException\u001b[0m: Program terminated with status: 1. stderr follows: Error: not well-formed (invalid token) in line 1 \r\n... <HTML>native-country_Trinadad&Tobago &le; 0.5 ...\r\nin label of node 2031\r\nError: not well-formed (invalid token) in line 1 \r\n... <HTML>native-country_Trinadad&Tobago &le; 0.5 ...\r\nin label of node 6622\r\ndot: graph is too large for cairo-renderer bitmaps. Scaling by 0.238349 to fit\r\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = X.columns,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('diabetes.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "65b65c77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of feature_names, 89 does not match number of features, 87",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18620/681020149.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m export_graphviz(clf, out_file=dot_data,  \n\u001b[0m\u001b[0;32m      8\u001b[0m                 \u001b[0mfilled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[1;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision, fontname)\u001b[0m\n\u001b[0;32m    886\u001b[0m             \u001b[0mfontname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfontname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         )\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[0mexporter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_string\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_export.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(self, decision_tree)\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    452\u001b[0m                     \u001b[1;34m\"Length of feature_names, %d does not match number of features, %d\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                     \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of feature_names, 89 does not match number of features, 87"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('diabetes.png')\n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3647b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = []\n",
    "a_train = []\n",
    "a_test = []\n",
    "for depth in range(1,19):\n",
    "    ax.append(depth)\n",
    "    dt = DecisionTreeClassifier(criterion='gini',max_depth=depth, max_leaf_nodes = 49)\n",
    "    dt.fit(X_train,y_train)\n",
    "    a_train.append(dt.score(X_test,y_test))\n",
    "#     dt.fit(Xt,yt)\n",
    "    a_test.append(dt.score(Xt,yt))\n",
    "    \n",
    "print(a_train)\n",
    "plt.plot(ax, a_train,label='train')\n",
    "print(a_test)\n",
    "plt.plot(ax, a_test,label='test')\n",
    "plt.xticks(ax)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=======training_data=======\")\n",
    "train_best = max(a_train)\n",
    "for i in range(len(a_train)):\n",
    "    if a_train[i]==train_best:\n",
    "        print(f' depth : {i} , acc : {train_best:.3f}')\n",
    "        break\n",
    "        \n",
    "print(\"=======test_data=======\")\n",
    "test_best = max(a_test)\n",
    "for i in range(len(a_train)):\n",
    "    if a_test[i]==test_best:\n",
    "        print(f' depth : {i} , acc : {test_best:.3f}')\n",
    "        best_depth = i+1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030a8f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = []\n",
    "a_train = []\n",
    "a_test = []\n",
    "for node in range(2,100):\n",
    "    ax.append(node)\n",
    "    dt = DecisionTreeClassifier(criterion='gini',max_depth=best_depth, max_leaf_nodes = node)\n",
    "    dt.fit(X_train,y_train)\n",
    "    a_train.append(dt.score(X_test,y_test))\n",
    "#     dt.fit(Xt,yt)\n",
    "    a_test.append(dt.score(Xt,yt))\n",
    "\n",
    "print(a_train)\n",
    "plt.plot(ax, a_train,label='train')\n",
    "print(a_test)\n",
    "plt.plot(ax, a_test,label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3bb549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1max = max(a_train)\n",
    "# t2max = max(a_test)\n",
    "# node1 = []\n",
    "# node2 = []\n",
    "# for i in range(len(a_train)):\n",
    "#     if a_train[i]==t1max:\n",
    "#         node1.append(i+1)\n",
    "\n",
    "# for i in range(len(a_test)):\n",
    "#     if a_test[i]==t2max:\n",
    "#         node2.append(i+1)\n",
    "\n",
    "# best_node1 = min(node1)\n",
    "# best_node2 = min(node2)\n",
    "# print(f'best_node1：{best_node1} & best_node2：{best_node2}')\n",
    "\n",
    "print(\"=======training_data=======\")\n",
    "train_best = max(a_train)\n",
    "for i in range(len(a_train)):\n",
    "    if a_train[i]==train_best:\n",
    "        print(f' node : {i+1} , acc : {train_best:.3f}')\n",
    "        best_node1 = i+1\n",
    "        break\n",
    "        \n",
    "print(\"=======test_data=======\")\n",
    "test_best = max(a_test)\n",
    "for i in range(len(a_train)):\n",
    "    if a_test[i]==test_best:\n",
    "        print(f' node : {i+1} , acc : {test_best:.3f}')\n",
    "        best_node2 = i+1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b5bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = []\n",
    "a_train = []\n",
    "a_test = []\n",
    "for depth in range(1,19):\n",
    "    ax.append(depth)\n",
    "    dt = DecisionTreeClassifier(criterion='gini',max_depth=depth, max_leaf_nodes = best_node1)\n",
    "    dt.fit(X_train,y_train)\n",
    "    a_train.append(dt.score(X_test,y_test))\n",
    "#     dt.fit(Xt,yt)\n",
    "    dt = DecisionTreeClassifier(criterion='gini',max_depth=depth, max_leaf_nodes = best_node2)\n",
    "    dt.fit(X_train,y_train)\n",
    "    a_test.append(dt.score(Xt,yt))\n",
    "    \n",
    "print(a_train)\n",
    "plt.plot(ax, a_train,label='train')\n",
    "print(a_test)\n",
    "plt.plot(ax, a_test,label='test')\n",
    "plt.xticks(ax)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb40008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=======training_data=======\")\n",
    "train_best = max(a_train)\n",
    "for i in range(len(a_train)):\n",
    "    if a_train[i]==train_best:\n",
    "        print(f' depth : {i+1} , acc : {train_best:.3f}')\n",
    "        break\n",
    "        \n",
    "print(\"=======test_data=======\")\n",
    "test_best = max(a_test)\n",
    "for i in range(len(a_train)):\n",
    "    if a_test[i]==test_best:\n",
    "        print(f' depth : {i+1} , acc : {test_best:.3f}')\n",
    "        best_depth = i+1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108fca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "dt = DecisionTreeClassifier(criterion='gini',max_depth=best_depth, max_leaf_nodes = best_node2)\n",
    "dt.fit(X_train,y_train)\n",
    "tree.plot_tree(dt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67deb4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "# _ = tree.plot_tree(dt,filled=True)\n",
    "_ = tree.plot_tree(dt, feature_names = feature_cols, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7cc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' best_depth：{best_depth} & best_node：{best_node2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cyj #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
